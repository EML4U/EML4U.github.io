%
% Source: https://citation-needed.springer.com/v2/references/10.1007/978-3-030-91608-4_11?format=bibtex&flavour=citation
@inproceedings{feldhans2021drift,
	title        = {Drift Detection in Text Data with Document Embeddings},
	author       = {Feldhans, Robert and Wilke, Adrian and Heindorf, Stefan and Shaker, Mohammad Hossein and Hammer, Barbara and Ngonga Ngomo, Axel-Cyrille and H{\"u}llermeier, Eyke},
	year         = 2021,
	booktitle    = {Intelligent Data Engineering and Automated Learning -- IDEAL 2021},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {107--118},
	doi          = {10.1007/978-3-030-91608-4_11},
	isbn         = {978-3-030-91608-4},
	editor       = {Yin, Hujun and Camacho, David and Tino, Peter and Allmendinger, Richard and Tall{\'o}n-Ballesteros, Antonio J. and Tang, Ke and Cho, Sung-Bae and Novais, Paulo and Nascimento, Susana},
	abstract     = {Collections of text documents such as product reviews and microblogs often evolve over time. In practice, however, classifiers trained on them are updated infrequently, leading to performance degradation over time.While approaches for automatic drift detection have been proposed, they were often designed for low-dimensional sensor data, and it is unclear how well they perform for state-of-the-art text classifiers based on high-dimensional document embeddings. In this paper, we empirically compare drift detectors on document embeddings on two benchmarking datasets with varying amounts of drift. Our results show that multivariate drift detectors based on the Kernel Two-Sample Test and Least-Squares Density Difference outperform univariate drift detectors based on the Kolmogorov-Smirnov Test. Moreover, our experiments show that current drift detectors perform better on smaller embedding dimensions.}
}
%
% Source: https://citation-needed.springer.com/v2/references/10.1007/s11063-022-10826-5?format=bibtex&flavour=citation
@article{Artelt2022,
	title        = {Contrasting Explanations for Understanding and Regularizing Model Adaptations},
	author       = {Artelt, Andr{\'e} and Hinder, Fabian and Vaquet, Valerie and Feldhans, Robert and Hammer, Barbara},
	year         = 2022,
	journal      = {Neural Processing Letters},
	doi          = {10.1007/s11063-022-10826-5},
	issn         = {1573-773X},
	url          = {https://doi.org/10.1007/s11063-022-10826-5},
	abstract     = {Many of today's decision making systems deployed in the real world are not static---they are changing and adapting over time, a phenomenon known as model adaptation takes place. Because of their wide reaching influence and potentially serious consequences, the need for transparency and interpretability of AI-based decision making systems is widely accepted and thus have been worked on extensively---e.g. a very prominent class of explanations are contrasting explanations which try to mimic human explanations. However, usually, explanation methods assume a static system that has to be explained. Explaining non-static systems is still an open research question, which poses the challenge how to explain model differences, adaptations and changes. In this contribution, we propose and (empirically) evaluate a general framework for explaining model adaptations and differences by contrasting explanations. We also propose a method for automatically finding regions in data space that are affected by a given model adaptation---i.e. regions where the internal reasoning of the other (e.g. adapted) model changed---and thus should be explained. Finally, we also propose a regularization for model adaptations to ensure that the internal reasoning of the adapted model does not change in an unwanted way.}
}
%
% Source: https://arxiv.org/abs/2107.10384
% Also published here: https://publikationen.bibliothek.kit.edu/1000138532
@misc{shaker2021ensemble,
	title        = {Ensemble-based Uncertainty Quantification: Bayesian versus Credal Inference},
	author       = {Shaker, Mohammad Hossein and Hüllermeier, Eyke},
	year         = 2021,
	publisher    = {preprint},
	doi          = {10.48550/ARXIV.2107.10384},
	url          = {https://arxiv.org/abs/2107.10384},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
%
% Source: https://ieeexplore.ieee.org/document/9522108
@article{zahera2021i,
	title        = {I-AID: Identifying Actionable Information From Disaster-Related Tweets},
	author       = {Zahera, Hamada M. and Jalota, Rricha and Sherif, Mohamed Ahmed and Ngomo, Axel-Cyrille Ngonga},
	year         = 2021,
	journal      = {IEEE Access},
	volume       = 9,
	number       = {},
	pages        = {118861--118870},
	doi          = {10.1109/ACCESS.2021.3107812}
}
%
% Source: https://www.bibsonomy.org/bibtex/2ba785e57acbd764032abb638a873fb8d/dice-research
@inproceedings{zahera2022multpax,
	title        = {MultPAX: Keyphrase Extraction using Language Models and Knowledge Graphs},
	author       = {Zahera, Hamada M. and Vollmers, Daniel and Sherif, Mohamed Ahmed and Ngomo, Axel-Cyrille Ngonga},
	year         = 2022,
	booktitle    = {{ISWC}},
	publisher    = {Springer},
	url          = {https://papers.dice-research.org/2022/ISWC-MultPAX/public.pdf},
	keywords     = {colide dice eml4u ngonga raki sherif speaker vollmers zahera},
}
%
% Source: https://www.bibsonomy.org/bibtex/23ad60ed7c1c815965699a18fbdf5b015/dice-research
@inproceedings{Bondarenko2022CausalQA,
  author = {Bondarenko, Alexander and Wolska, Magdalena and Heindorf, Stefan and Bl{\"u}baum, Lukas and Ngomo, Axel-Cyrille Ngonga and Stein, Benno and Braslavski, Pavel and Hagen, Matthias and Potthast, Martin},
  booktitle = {COLING},
  keywords = {colide dice eml4u heindorf ngonga raki},
  pages = {3296--3308},
  title = {CausalQA: A Benchmark for Causal Question Answering},
  url = {https://aclanthology.org/2022.coling-1.291.pdf},
  year = 2022
}
%
% Source: https://arxiv.org/abs/2203.14603
@misc{Schroeder2022SameScore,
    doi = {10.48550/ARXIV.2203.14603},
    url = {https://arxiv.org/abs/2203.14603},
    author = {Schröder, Sarah and Schulz, Alexander and Kenneweg, Philip and Feldhans, Robert and Hinder, Fabian and Hammer, Barbara},
    keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {The SAME score: Improved cosine based bias score for word embeddings},
    publisher = {arXiv},
    year = {2022},
    copyright = {Creative Commons Attribution 4.0 International}
}

